{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry was an empty string: -- (should be empty)\n",
      "Entry was an empty string: -- (should be empty)\n",
      "Entry was an empty string: -- (should be empty)\n",
      "Entry was an empty string: -- (should be empty)\n",
      "Entry was an empty string: -- (should be empty)\n",
      "Entry was an empty string: -- (should be empty)\n",
      "Entry X is not a number.\n",
      "Entry XX is not a number.\n",
      "Entry XX is not a number.\n",
      "Entry was an empty string: -- (should be empty)\n",
      "Entry was an empty string: -- (should be empty)\n",
      "Entry was an empty string: -- (should be empty)\n",
      "Entry was an empty string: -- (should be empty)\n",
      "Shape of df is: (191652, 80)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as snsy\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Load in the general demographics data.\n",
    "azdias = pd.read_csv(\"Udacity_CUSTOMERS_Subset.csv\", delimiter = \";\")\n",
    "\n",
    "\n",
    "# Load in the feature summary file.\n",
    "feat_info = pd.read_csv(\"AZDIAS_Feature_Summary.csv\", delimiter = \";\")\n",
    "\n",
    "# Identify missing or unknown data values and convert them to NaNs.\n",
    "def list_convert(line):\n",
    "    line = line.replace(\"[\", \"\")\n",
    "    line = line.replace(\"]\", \"\")\n",
    "    a = line.split(\",\")\n",
    "    return a\n",
    "feat_info[\"missing_or_unknown\"] = feat_info[\"missing_or_unknown\"].apply(list_convert)\n",
    "# Sets the attribute as index so it is easier to handle with the .loc mehtod\n",
    "feat_info.set_index(\"attribute\", inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "# Iterates through the columns of azdias\n",
    "for column in azdias.columns:\n",
    "    # saves the values as a list which are nan in this colum\n",
    "    null_values = feat_info.loc[str(column), \"missing_or_unknown\"]\n",
    "    for entry in null_values:\n",
    "        # Some columns do not have an indicator for null values,\n",
    "        try:\n",
    "            if (entry != \"\"):\n",
    "                # replaces every null value with an np.nan in the column\n",
    "                azdias[column] = azdias[column].replace(int(entry), np.nan)\n",
    "            else:\n",
    "                print(\"Entry was an empty string: -{}- (should be empty)\".format(entry))\n",
    "        except:\n",
    "            print(\"Entry {} is not a number.\".format(entry))\n",
    "            azdias[column] = azdias[column].replace(entry, np.nan)\n",
    "\n",
    "nan_columns = [\"AGER_TYP\", \"GEBURTSJAHR\", \"TITEL_KZ\", \"ALTER_HH\", \"HH_EINKOMMEN_SCORE\"]\n",
    "# drop columns\n",
    "azdias.drop(axis = 1, columns = nan_columns, inplace = True)\n",
    "len(azdias.columns)\n",
    "print(\"Shape of df is: {}\".format(azdias.shape))\n",
    "\n",
    "# How much data is missing in each row of the dataset?\n",
    "azdias[\"missing\"] = azdias.apply(lambda x: (azdias.shape[1] - x.count()), axis=1)\n",
    "\n",
    "df_full = azdias.query(\"missing == 0\")\n",
    "print(\"Shape is now: {}\".format(df_full.shape))\n",
    "\n",
    "# How many features are there of each data type?\n",
    "cat_mixed_info = feat_info.query(\"type == ['categorical', 'mixed']\")\n",
    "cat_columns = list(feat_info.query(\"type == ['categorical']\").index)\n",
    "one_hot = []\n",
    "\n",
    "for column in cat_columns:\n",
    "    try:\n",
    "        print(\"Column {} has {} unique values\".format(column,len(df_full[column].unique())))\n",
    "        # If it is already one hot encoded do nothing\n",
    "        if list(df_full[column].unique()) == [0, 1]:\n",
    "            pass\n",
    "        # Otherwise append it to a list for one-hot encoding\n",
    "        else:\n",
    "            one_hot.append(column)\n",
    "    except KeyError:\n",
    "        print(\"The column {} got removed in an earlier step\".format(column))\n",
    "\n",
    "df_oh = df_full.copy()\n",
    "# Re-encode categorical variable(s) to be kept in the analysis.\n",
    "df_oh = pd.get_dummies(data = df_oh, columns = list(one_hot))\n",
    "\n",
    "print(\"Shape of df is now {}\".format(df_oh.shape))\n",
    "\n",
    "# Engineer new variables\n",
    "mainstream = [1,3,5,8,10,12,14]\n",
    "\n",
    "df_oh[\"MAINSTREAM\"] = 2\n",
    "for number in mainstream:\n",
    "    df_oh.loc[df_oh.PRAEGENDE_JUGENDJAHRE == number, 'MAINSTREAM'] = \"1\"\n",
    "df_oh[\"MAINSTREAM\"].replace(2, 0, inplace = True)\n",
    "\n",
    "df_oh[\"GENERATION\"] = 30\n",
    "gen_dict = {1:40, 2:40, 3:50, 4:50, 5:60, 6:60, 7:60, 8:70, 8:70, 9:70, 10: 80, 11:80,\n",
    "           12:80, 13: 80, 14:90, 15:90}\n",
    "for key, value in gen_dict.items():\n",
    "    df_oh.loc[df_oh.PRAEGENDE_JUGENDJAHRE == key, \"GENERATION\"] = value\n",
    "\n",
    "df_oh[\"WEALTH\"] = df_oh[\"CAMEO_INTL_2015\"].str[:1]\n",
    "df_oh[\"LIFE_STAGE\"] = df_oh[\"CAMEO_INTL_2015\"].str[1:]\n",
    "\n",
    "# LP_LEBENSPHASE_GROB is a subset of LP_LEBENSPHASE_FEIN and is therefore dropped\n",
    "df_oh.drop(columns = \"LP_LEBENSPHASE_GROB\", inplace = True)\n",
    "\n",
    "mixed_oh_01 = [\"GENERATION\",\"WEALTH\", \"LIFE_STAGE\",\n",
    "            \"LP_LEBENSPHASE_FEIN\"]\n",
    "mixed_oh_02 = [\"WOHNLAGE\", \"KBA05_BAUMAX\", \"PLZ8_BAUMAX\"]\n",
    "\n",
    "\n",
    "\n",
    "df_oh = pd.get_dummies(data = df_oh, columns = mixed_oh_01)\n",
    "df_oh[\"WOHNLAGE_0.0\"] = 0\n",
    "df_oh = pd.get_dummies(data = df_oh, columns = mixed_oh_02)\n",
    "print(\"The shape is now {}\".format(df_oh.shape))\n",
    "\n",
    "drop_cols = [\"PRAEGENDE_JUGENDJAHRE\", \"CAMEO_INTL_2015\"]\n",
    "df_oh.drop(columns = drop_cols, inplace = True)\n",
    "\n",
    "print(\"The shape is now {}\".format(df_oh.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
